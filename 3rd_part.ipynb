{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd part: Testing the potential reasons for their causality for the miss predictions <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Testing the filled in NaNs for error causality\n",
    "<br>\n",
    "Now we are going to test if we ourselves are responsible for the false predictions by adding flawed information when we filled in the NaNs. We are going test this by adding information to the dataset about whether a loan contains a filled in former NaN value. We will achieve this by adding one extra column for each column that contained NaNs. If a row has a filled in NaN, we are going to add \"Y\" as a value in the newly added corresponding column otherwise we add \"N\". We then ordinally encode these features of the new columns, so the machine knows, that an filled NaN is inferior to a value that was present from the beginning. This way, if the random forest performs better, we will know that we added flawed information the way we filled in the NaNs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Importing and complementing required code from the previous part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_df = pd.read_csv(\"https://github.com/TomMarq1/Credit_default_prediction_-ML-model-/raw/main/credit_risk_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add additional information regarding filled NaNs in \"person_emp_length\" and in \"loan_int_rate\"\n",
    "raw_df[\"person_emp_length_filled_in\"] = \"N\"\n",
    "raw_df[\"loan_int_rate_filled_in\"] = \"N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add \"Y\" in \"person_emp_length_filled_in\" for every row that has NaN in \"person_emp_lenght\"\n",
    "raw_df.loc[raw_df[\"person_emp_length\"].isna(), [\"person_emp_length_filled_in\"]] = \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add \"Y\" in \"loan_int_rate_filled_in\" for every row that has NaN in \"loan_int_rage\"\n",
    "raw_df.loc[raw_df[\"loan_int_rate\"].isna(), [\"loan_int_rate_filled_in\"]] = \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = raw_df.copy()\n",
    "cleaned_df[\"person_emp_length\"].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df[\"loan_int_rate\"].fillna(cleaned_df[\"loan_int_rate\"].median(), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_df.drop(columns=[\"loan_status\"])\n",
    "y = cleaned_df[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = X_train.select_dtypes(\"number\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_num_col_scaled = sc.fit_transform(X_train[num_col])\n",
    "X_test_num_col_scaled = sc.transform(X_test[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = X_train.select_dtypes(\"object\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person_home_ownership',\n",
       " 'loan_intent',\n",
       " 'loan_grade',\n",
       " 'cb_person_default_on_file',\n",
       " 'person_emp_length_filled_in',\n",
       " 'loan_int_rate_filled_in']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ord_category_col = [cat_col[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohenc = OneHotEncoder(sparse=False)\n",
    "X_train_non_ord_cat_col_enc = ohenc.fit_transform(X_train[non_ord_category_col])\n",
    "X_test_non_ord_cat_col_enc = ohenc.transform(X_test[non_ord_category_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_grade',\n",
       " 'person_home_ownership',\n",
       " 'person_emp_length_filled_in',\n",
       " 'cb_person_default_on_file',\n",
       " 'loan_int_rate_filled_in']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_category_col = list((set(X_train.columns.to_list()) - set(num_col) - set(non_ord_category_col)))\n",
    "ord_category_col\n",
    "\n",
    "## for unkown reasons the order of the items in ord_category_col change every time the notebook is run. This can lead to an error in the cell 2 below. \n",
    "## to resolve the error rearrange the item order in cats_ord in the cell one below according to the item order of ord_category_col in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "person_emp_length_filled_in_cats = [\"Y\", \"N\"]\n",
    "cb_person_default_on_file_cats = [\"Y\", \"N\"]\n",
    "loan_grade_cats =[\"G\", \"F\", \"E\", \"D\", \"C\", \"B\", \"A\"]\n",
    "loan_int_rate_filled_in_cats = [\"Y\", \"N\"]\n",
    "person_home_ownership_cats = [\"OTHER\", \"RENT\", \"MORTGAGE\", \"OWN\"]\n",
    "\n",
    "cats_ord = [loan_grade_cats, person_home_ownership_cats, person_emp_length_filled_in_cats, cb_person_default_on_file_cats, loan_int_rate_filled_in_cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If an error occurs, look at comment 2 cells above to fix it.\n",
    "ord_enc = OrdinalEncoder(categories= cats_ord)\n",
    "X_train_ord_cat_enc = ord_enc.fit_transform(X_train[ord_category_col])\n",
    "X_test_ord_cat_enc = ord_enc.transform(X_test[ord_category_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = pd.concat([pd.DataFrame(X_train_num_col_scaled, #dataframe with scaled numerical columns\n",
    "                               columns = num_col),\n",
    "                               pd.DataFrame(X_train_non_ord_cat_col_enc, #dataframe with encoded non ordinal categorical columns\n",
    "                               columns = ohenc.get_feature_names_out()),\n",
    "                               pd.DataFrame(X_train_ord_cat_enc, # dataframe with encoded ordinal categorical columns\n",
    "                               columns = ord_category_col) \n",
    "\n",
    "                               \n",
    "                               ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_processed = pd.concat([pd.DataFrame(X_test_num_col_scaled, #dataframe with scaled numerical columns\n",
    "                               columns = num_col),\n",
    "                               pd.DataFrame(X_test_non_ord_cat_col_enc, #dataframe with encoded non ordinal categorical columns\n",
    "                               columns = ohenc.get_feature_names_out()),\n",
    "                               pd.DataFrame(X_test_ord_cat_enc, # dataframe with encoded ordinal categorical columns\n",
    "                               columns = ord_category_col) \n",
    "\n",
    "                               \n",
    "                               ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Train a random forest with the dataset which contains the added information with the hyperparameters we found with gridsearchCV in the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272398748402451"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(random_forest.predict(X_train_processed), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9274035989717224"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(random_forest.predict(X_test_processed), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Result\n",
    "<br>\n",
    "The random forest trained with added information performs slightly better with 92.74% accuracy compared to    92.72% without the added information. This increase in performance is in the margin of randomness so we can conclude that adding the information did not increase performance significantly and therby that we did not cause the false predictions by adding flawed informatin when filling in the NaNs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Testing \"loan_grade > 3.5\" as a source of the errors\n",
    "<br>\n",
    "Lastly we are going to test whether a value in \"loan_grade\" which is larger then 3.5 (=loan_grade C or better) contains flawed information because most of the miss predictions have such a value. To do so we are going to split up the dataset into 2 groups. One group contains loans with \"loan_grade\" <= 3.5 \n",
    "(=loan_grade D or worse), the other group contains loans with \"loan_grade\" > 3.5 (=loan_grade C or better). \n",
    "<br>\n",
    "If the value loan_grade > 3.5 is flawed, then having no loans of this kind in the group should result in a better prediction performance for this group compared to the prediction for the whole dataset.\n",
    "<br>\n",
    "Also if loan_grade > 3.5 is flawed , then having only such loans in one group and dropping these potentially flawed values by dropping the whole column \"loan_grade\", should result in higher performance compared to the same group without dropping the column with the potentially flawed values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Testing group \"loan_grade\" <= 3.5 (loan grade D to G) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_grade D to G\n",
    "import pandas as pd\n",
    "raw_df = pd.read_csv(\"https://github.com/TomMarq1/Credit_default_prediction_-ML-model-/raw/main/credit_risk_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = raw_df.copy()\n",
    "cleaned_df[\"person_emp_length\"].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_grade_categories = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "cleaned_df[\"loan_int_rate\"].fillna(cleaned_df[\"loan_int_rate\"].median(), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = cleaned_df.query(\"loan_grade == ['D', 'E', 'F', 'G']\").drop(columns=[\"loan_status\"])\n",
    "y2 = cleaned_df.query(\"loan_grade == ['D', 'E', 'F', 'G']\")[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = X_train2.select_dtypes(\"number\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train2_num_col_scaled = sc.fit_transform(X_train2[num_col])\n",
    "X_test2_num_col_scaled = sc.transform(X_test2[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = X_train2.select_dtypes(\"object\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ord_category_col = [cat_col[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohenc = OneHotEncoder(sparse=False)\n",
    "X_train2_non_ord_cat_col_enc = ohenc.fit_transform(X_train2[non_ord_category_col])\n",
    "X_test2_non_ord_cat_col_enc = ohenc.transform(X_test2[non_ord_category_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_grade', 'person_home_ownership', 'cb_person_default_on_file']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_category_col = list((set(X_train2.columns.to_list()) - set(num_col) - set(non_ord_category_col)))\n",
    "ord_category_col\n",
    "## for unkown reasons the order of the items in ord_category_col change every time the notebook is run. This can lead to an error in the cell 2 below. \n",
    "## to resolve the error rearrange the item order in cats_ord in the cell one below according to the item order of ord_category_col in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_person_default_on_file_cats = [\"Y\", \"N\"]\n",
    "loan_grade_cats =[\"G\", \"F\", \"E\", \"D\", \"C\", \"B\", \"A\"]\n",
    "person_home_ownership_cats = [\"OTHER\", \"RENT\", \"MORTGAGE\", \"OWN\"]\n",
    "\n",
    "cats_ord = [loan_grade_cats, person_home_ownership_cats, cb_person_default_on_file_cats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if error occurs, see comment 2 cells above for fixing.\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ord_enc = OrdinalEncoder(categories= cats_ord)\n",
    "X_train2_ord_cat_enc = ord_enc.fit_transform(X_train2[ord_category_col])\n",
    "X_test2_ord_cat_enc = ord_enc.transform(X_test2[ord_category_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_processed = pd.concat([pd.DataFrame(X_train2_num_col_scaled, #dataframe with scaled numerical columns\n",
    "                               columns = num_col),\n",
    "                               pd.DataFrame(X_train2_non_ord_cat_col_enc, #dataframe with encoded non ordinal categorical columns\n",
    "                               columns = ohenc.get_feature_names_out()),\n",
    "                               pd.DataFrame(X_train2_ord_cat_enc, # dataframe with encoded ordinal categorical columns\n",
    "                               columns = ord_category_col) \n",
    "\n",
    "                               \n",
    "                               ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2_processed = pd.concat([pd.DataFrame(X_test2_num_col_scaled, #dataframe with scaled numerical columns\n",
    "                               columns = num_col),\n",
    "                               pd.DataFrame(X_test2_non_ord_cat_col_enc, #dataframe with encoded non ordinal categorical columns\n",
    "                               columns = ohenc.get_feature_names_out()),\n",
    "                               pd.DataFrame(X_test2_ord_cat_enc, # dataframe with encoded ordinal categorical columns\n",
    "                               columns = ord_category_col) \n",
    "\n",
    "                               \n",
    "                               ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_intent_DEBTCONSOLIDATION</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.620776</td>\n",
       "      <td>3.689454</td>\n",
       "      <td>0.958256</td>\n",
       "      <td>1.803236</td>\n",
       "      <td>-0.420820</td>\n",
       "      <td>-0.861115</td>\n",
       "      <td>0.243019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.621865</td>\n",
       "      <td>-0.771813</td>\n",
       "      <td>-1.010223</td>\n",
       "      <td>-0.787060</td>\n",
       "      <td>-0.650251</td>\n",
       "      <td>0.052253</td>\n",
       "      <td>-0.942658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.311204</td>\n",
       "      <td>-0.972771</td>\n",
       "      <td>-0.572783</td>\n",
       "      <td>-1.267734</td>\n",
       "      <td>-1.050536</td>\n",
       "      <td>-0.769778</td>\n",
       "      <td>-0.942658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.465446</td>\n",
       "      <td>-0.080518</td>\n",
       "      <td>0.739536</td>\n",
       "      <td>-0.399851</td>\n",
       "      <td>-0.664896</td>\n",
       "      <td>-0.495767</td>\n",
       "      <td>-0.231252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.931437</td>\n",
       "      <td>0.715276</td>\n",
       "      <td>-0.135343</td>\n",
       "      <td>-0.413203</td>\n",
       "      <td>0.848373</td>\n",
       "      <td>-1.043788</td>\n",
       "      <td>0.954425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>0.776107</td>\n",
       "      <td>-0.450280</td>\n",
       "      <td>0.302096</td>\n",
       "      <td>-0.933933</td>\n",
       "      <td>-0.347598</td>\n",
       "      <td>-0.861115</td>\n",
       "      <td>0.954425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>-0.466534</td>\n",
       "      <td>-0.369897</td>\n",
       "      <td>0.520816</td>\n",
       "      <td>-0.333091</td>\n",
       "      <td>-0.196271</td>\n",
       "      <td>-0.039083</td>\n",
       "      <td>-0.705523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>-0.621865</td>\n",
       "      <td>-0.430184</td>\n",
       "      <td>-1.010223</td>\n",
       "      <td>-0.733652</td>\n",
       "      <td>0.848373</td>\n",
       "      <td>-0.587104</td>\n",
       "      <td>-0.705523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>-0.777195</td>\n",
       "      <td>0.574605</td>\n",
       "      <td>0.520816</td>\n",
       "      <td>1.803236</td>\n",
       "      <td>1.624534</td>\n",
       "      <td>0.600274</td>\n",
       "      <td>-0.468387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>-0.466534</td>\n",
       "      <td>0.976521</td>\n",
       "      <td>-0.791503</td>\n",
       "      <td>1.135634</td>\n",
       "      <td>0.096620</td>\n",
       "      <td>-0.221757</td>\n",
       "      <td>-0.942658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1469 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      person_age  person_income  person_emp_length  loan_amnt  loan_int_rate  \\\n",
       "0       0.620776       3.689454           0.958256   1.803236      -0.420820   \n",
       "1      -0.621865      -0.771813          -1.010223  -0.787060      -0.650251   \n",
       "2      -0.311204      -0.972771          -0.572783  -1.267734      -1.050536   \n",
       "3       0.465446      -0.080518           0.739536  -0.399851      -0.664896   \n",
       "4       0.931437       0.715276          -0.135343  -0.413203       0.848373   \n",
       "...          ...            ...                ...        ...            ...   \n",
       "1464    0.776107      -0.450280           0.302096  -0.933933      -0.347598   \n",
       "1465   -0.466534      -0.369897           0.520816  -0.333091      -0.196271   \n",
       "1466   -0.621865      -0.430184          -1.010223  -0.733652       0.848373   \n",
       "1467   -0.777195       0.574605           0.520816   1.803236       1.624534   \n",
       "1468   -0.466534       0.976521          -0.791503   1.135634       0.096620   \n",
       "\n",
       "      loan_percent_income  cb_person_cred_hist_length  \\\n",
       "0               -0.861115                    0.243019   \n",
       "1                0.052253                   -0.942658   \n",
       "2               -0.769778                   -0.942658   \n",
       "3               -0.495767                   -0.231252   \n",
       "4               -1.043788                    0.954425   \n",
       "...                   ...                         ...   \n",
       "1464            -0.861115                    0.954425   \n",
       "1465            -0.039083                   -0.705523   \n",
       "1466            -0.587104                   -0.705523   \n",
       "1467             0.600274                   -0.468387   \n",
       "1468            -0.221757                   -0.942658   \n",
       "\n",
       "      loan_intent_DEBTCONSOLIDATION  loan_intent_EDUCATION  \\\n",
       "0                               0.0                    0.0   \n",
       "1                               0.0                    0.0   \n",
       "2                               0.0                    1.0   \n",
       "3                               0.0                    1.0   \n",
       "4                               0.0                    1.0   \n",
       "...                             ...                    ...   \n",
       "1464                            1.0                    0.0   \n",
       "1465                            0.0                    0.0   \n",
       "1466                            0.0                    1.0   \n",
       "1467                            0.0                    0.0   \n",
       "1468                            0.0                    1.0   \n",
       "\n",
       "      loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  loan_intent_PERSONAL  \\\n",
       "0                             0.0                  0.0                   0.0   \n",
       "1                             0.0                  0.0                   1.0   \n",
       "2                             0.0                  0.0                   0.0   \n",
       "3                             0.0                  0.0                   0.0   \n",
       "4                             0.0                  0.0                   0.0   \n",
       "...                           ...                  ...                   ...   \n",
       "1464                          0.0                  0.0                   0.0   \n",
       "1465                          1.0                  0.0                   0.0   \n",
       "1466                          0.0                  0.0                   0.0   \n",
       "1467                          0.0                  0.0                   1.0   \n",
       "1468                          0.0                  0.0                   0.0   \n",
       "\n",
       "      loan_intent_VENTURE  loan_grade  person_home_ownership  \\\n",
       "0                     1.0         3.0                    2.0   \n",
       "1                     0.0         3.0                    1.0   \n",
       "2                     0.0         3.0                    1.0   \n",
       "3                     0.0         3.0                    2.0   \n",
       "4                     0.0         2.0                    1.0   \n",
       "...                   ...         ...                    ...   \n",
       "1464                  0.0         3.0                    2.0   \n",
       "1465                  0.0         3.0                    1.0   \n",
       "1466                  0.0         2.0                    1.0   \n",
       "1467                  0.0         1.0                    2.0   \n",
       "1468                  0.0         3.0                    2.0   \n",
       "\n",
       "      cb_person_default_on_file  \n",
       "0                           1.0  \n",
       "1                           0.0  \n",
       "2                           1.0  \n",
       "3                           1.0  \n",
       "4                           0.0  \n",
       "...                         ...  \n",
       "1464                        1.0  \n",
       "1465                        0.0  \n",
       "1466                        0.0  \n",
       "1467                        1.0  \n",
       "1468                        0.0  \n",
       "\n",
       "[1469 rows x 16 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Random forest with group d to g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random_forest2 = RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest2.fit(X_train2_processed, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8931698774080561"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(random_forest2.predict(X_train2_processed), y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8822328114363512"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(random_forest2.predict(X_test2_processed), y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Result\n",
    "<br>\n",
    "The random forest performed worse with the group not containing loans having \"loan_grade\" > 3.5 then with the mixed original dataset. This can mean that having a value \"loan_grade\" > 3.5 is not flawed completly in every situation but instead provides useful information to learn how to predict the default of loans that have \"loan_grade\" <= 3.5. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Testing \"loan_grade\" <= 3.5 (loan grade A to C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = cleaned_df.query(\"loan_grade == ['A', 'B', 'C']\").drop(columns=[\"loan_status\"])\n",
    "y1 = cleaned_df.query(\"loan_grade == ['A', 'B', 'C']\")[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.3, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = X_train2.select_dtypes(\"number\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train1_num_col_scaled = sc.fit_transform(X_train1[num_col])\n",
    "X_test1_num_col_scaled = sc.transform(X_test1[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = X_train1.select_dtypes(\"object\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ord_category_col = [cat_col[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohenc = OneHotEncoder(sparse=False)\n",
    "X_train1_non_ord_cat_col_enc = ohenc.fit_transform(X_train1[non_ord_category_col])\n",
    "X_test1_non_ord_cat_col_enc = ohenc.transform(X_test1[non_ord_category_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_grade', 'person_home_ownership', 'cb_person_default_on_file']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_category_col = list((set(X_train1.columns.to_list()) - set(num_col) - set(non_ord_category_col)))\n",
    "ord_category_col\n",
    "\n",
    "## for unkown reasons the order of the items in ord_category_col change every time the notebook is run. This can lead to an error in the cell 2 below. \n",
    "## to resolve the error rearrange the item order in cats_ord in the cell one below according to the item order of ord_category_col in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_person_default_on_file_cats = [\"Y\", \"N\"]\n",
    "loan_grade_cats =[\"G\", \"F\", \"E\", \"D\", \"C\", \"B\", \"A\"]\n",
    "person_home_ownership_cats = [\"OTHER\", \"RENT\", \"MORTGAGE\", \"OWN\"]\n",
    "\n",
    "cats_ord = [loan_grade_cats, person_home_ownership_cats, cb_person_default_on_file_cats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if error occurs, see comment 2 cells above for fixing\n",
    "ord_enc = OrdinalEncoder(categories= cats_ord)\n",
    "X_train1_ord_cat_enc = ord_enc.fit_transform(X_train1[ord_category_col])\n",
    "X_test1_ord_cat_enc = ord_enc.transform(X_test1[ord_category_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1_processed = pd.concat([pd.DataFrame(X_train1_num_col_scaled, #dataframe with scaled numerical columns\n",
    "                               columns = num_col),\n",
    "                               pd.DataFrame(X_train1_non_ord_cat_col_enc, #dataframe with encoded non ordinal categorical columns\n",
    "                               columns = ohenc.get_feature_names_out()),\n",
    "                               pd.DataFrame(X_train1_ord_cat_enc, # dataframe with encoded ordinal categorical columns\n",
    "                               columns = ord_category_col) \n",
    "\n",
    "                               \n",
    "                               ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1_processed = pd.concat([pd.DataFrame(X_test1_num_col_scaled, #dataframe with scaled numerical columns\n",
    "                               columns = num_col),\n",
    "                               pd.DataFrame(X_test1_non_ord_cat_col_enc, #dataframe with encoded non ordinal categorical columns\n",
    "                               columns = ohenc.get_feature_names_out()),\n",
    "                               pd.DataFrame(X_test1_ord_cat_enc, # dataframe with encoded ordinal categorical columns\n",
    "                               columns = ord_category_col) \n",
    "\n",
    "                               \n",
    "                               ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Random forest with group a to c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.1 Random forest without column \"loan_grade\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest1 = RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest1.fit(X_train1_processed.drop(columns=[\"loan_grade\"]), y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9325593395252838"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(random_forest1.predict(X_train1_processed.drop(columns=[\"loan_grade\"])), y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9357091259330604"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(random_forest1.predict(X_test1_processed.drop(columns=[\"loan_grade\"])), y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.2 Random forest with column \"loan_grade\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest1 = RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest1.fit(X_train1_processed, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324045407636739"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(random_forest1.predict(X_train1_processed), y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9353479412472911"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(random_forest1.predict(X_test1_processed), y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Result\n",
    "<br>\n",
    "The random forest trained on the group only containing loans with \"loan_grade\" > 3.5 and in which the complete column \"loan_grade\" containing these potentially flawed values were dropped, performed almost identically to the random forest trained on the same group but keeping the column \"loan_grade\" (93.57% vs 93.53%).\n",
    "<br>\n",
    "This means that values \"loan_grade\" > 3.5 do not provide useful information for default prediction in a group consisting only of loans with \"loan_grade\" > 3.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Combined results\n",
    "<br>\n",
    "On the one hand \"loan_grade\" > 3.5 as described above does not provide helpful information for default prediction for loans that have such a value in this range themselves. On the other hand values in that range seem to provide information that is useful to make predictions about other loans that have a value of =< 3.5 in \"loan_grade\".\n",
    "<br>\n",
    "<br>\n",
    "The reason for this can unfortunately not be concluded from the dataset. But what can be said is that, if  loan grades from A to C do not provide information about the default possibility of loans with those values, then it is likely that the informations which were aggregated creating those values were not sufficient regarding predicting a default. By the disability to provide useful information about loan default for a certain group of loans, the \"loan_grade\" values A to C affect the dataquility of the whole dataset in a negative way.<br>\n",
    "<br> \n",
    "In this case the method which is used to create those values, probably a scoring model of its own, should be revised by the bank to improve the possibility of default predictions for those kind of loans. This way the bank could have an overall more reliable default prediction which is a basis of pricing loans accordingly which itself is a corner stone of succesful banking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Main takeaways about machine learning from this task\n",
    "<br>\n",
    "<br>\n",
    "My main takeaways about machine learning from this task are at first that there is basically an almost infinite number of iterations you can do to try to improve your model. All the possibilities of different machine learning models, different ways of filling NaNs, ways to rebalance a dataset, finding the right hyperparameters for a model and so on add up to a huge amount of possible combinations that all need to be tested to find the best possible outcome. Thereby building a machine learning model is strongly limited by the time you have to built it.\n",
    "<br>\n",
    "<br>\n",
    "Furthermore a main takeaway is that even though you had a lot of time for building a machine learning model, you can not overcome issues with data quality (in this case \"loan_grade\" > 3.5). No matter how many and different methods you try to improve the models performance, you can not overcome a certain treshold which is set by the data quality.\n",
    "<br>\n",
    "<br>\n",
    "Lastly the biggest takeaway for me personally was that the difficult and challenging thing about machine learning is not how to write the code but to explain to others what you have done, why, the findings and the conclusions of this complex matter in a way so that others can understand it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Transforming the gained knowledge of this project into business insights <br>\n",
    "<br>\n",
    "Generally this project shows how important data quality is when collecting and creating new data by aggregation. Only if a certain data quality can be ensured, it makes economically sense to spent ressources for collecting data and making business decisions based on that data. If data quality is not sufficient, machine learning models as well as deciders will make incorrect decisions based on this data without anyone even noticing until it´s too late and the damage is already done.<br>\n",
    "<br>\n",
    "In the instant case, as already mentioned above, the bank should revise the method which is used to create loan grade values from A to C, probably a scoring model of its own, to improve the possibility of default predictions for those kind of loans. This way the bank can have an overall more reliable default prediction which is a basis of pricing loans accordingly which itself is a corner stone of succesful banking. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fcd92e81d356c53c6d134a21843f5af27b4ea41bc107c08a34e03baf722d2b4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
